{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk8NF7ZkpQX3VHLQU7Qez4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanhhkhcndn/mobilenet-transfer-learning/blob/main/mobilenetSSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training MobileNetSSD Object Detection on a Custom Dataset\n",
        "## Overview\n",
        "This notebook walks through how to train a MobileNet object detection model using the TensorFlow 1.5 Object Detection API.\n",
        "\n",
        "In this specific example, we'll training an model to detect thief in edge devices.\n",
        "## **Our Data**\n",
        "\n",
        "We'll be using an image dataset from videos. Our dataset contains 614 images.\n",
        "We create two datasets in Roboflow: `train`, `test` and `valid`. Use Roboflow to generate TFRecords for each, replace their URLs in this notebook, and you're able to train on your own custom dataset.\n",
        "\n",
        "## **Our Model**\n",
        "\n",
        "We'll be training a MobileNetSSDv2 (single shot detector). This specific model is a one-short learner, meaning each image only passes through the network once to make a prediction, which allows the architecture to be very performant for low performace hardware.\n",
        "\n",
        "The model arechitecture is one of many available via TensorFlow's [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
        "\n",
        "As a note, this notebook presumes TensorFlow 1.5 as TensorFlow 2.0 has yet to fully support the object detection API.\n",
        "\n",
        "## **Training**\n",
        "\n",
        "Google Colab provides free GPU resources. Click \"Runtime\" → \"Change runtime type\" → Hardware Accelerator dropdown to \"GPU.\"\n",
        "\n",
        "Colab does have memory limitations, and notebooks must be open in your browser to run. Sessions automatically clear themselves after 12 hours.\n"
      ],
      "metadata": {
        "id": "FhGt-4PPZE6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Clone TensorFlow2 object detection API folder to your colab:"
      ],
      "metadata": {
        "id": "wJ3Zvd1_JJl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OCXzHCBaEqb",
        "outputId": "04a4da13-e40f-40a9-9133-e864e05ac349"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 4065, done.\u001b[K\n",
            "remote: Counting objects: 100% (4065/4065), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3089/3089), done.\u001b[K\n",
            "remote: Total 4065 (delta 1186), reused 1941 (delta 916), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4065/4065), 54.71 MiB | 23.91 MiB/s, done.\n",
            "Resolving deltas: 100% (1186/1186), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Install object detection API in colab\n",
        "pip install tensorflow[and-cuda]==2.13.0 --> fix error\n",
        "module 'tensorflow.python.ops.control_flow_ops' has no attribute 'case'"
      ],
      "metadata": {
        "id": "KpRg-qviaYPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd /content/models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install .\n",
        "pip install tensorflow[and-cuda]==2.13.0"
      ],
      "metadata": {
        "id": "T1VTwc8OajHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Import the TensorFlow libraries to colab"
      ],
      "metadata": {
        "id": "wSZMJngTbiDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "R_XmSiUKb1ZU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Run this command to test if object detection API is installed properly:"
      ],
      "metadata": {
        "id": "-TM4k3OJcBy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "zM8MgO0KcJsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Prepare custom set of images for training. I’m using Roboflow in this example to create the TFRecord file from the training images.\n",
        "Downloaded files will go to /content/train/ folder in colab environment."
      ],
      "metadata": {
        "id": "Ab_IqtjucEAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "#Download Training set from git by cloning rep:\n",
        "import os\n",
        "import pathlib\n",
        "# Clone the training set repository if it doesn't already exist\n",
        "if \"ThiefTFData\" in pathlib.Path.cwd().parts:\n",
        "  while \"ThiefTFData\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('ThiefTFData').exists():\n",
        "  !git clone --depth 1 https://github.com/tanhhkhcndn/mobilenet-transfer-learning/\n",
        "  %cd /content/mobilenet-transfer-learning/ThiefTFData\n",
        "#  !unzip Pickachu.v1.tfrecord.zip -d /content/\n",
        "\n",
        "#NOTE: Update these TFRecord names to your files containing training set!\n",
        "#Also, Update relevant rows:in training config file \"ssd_mobilenet_v2_320x320_coco17_tpu-8.config\"\n",
        "#label_map_path,input_path\n",
        "\n",
        "test_record_fname = '/content/mobilenet-transfer-learning/ThiefTFData/test/Thief.tfrecord'\n",
        "train_record_fname = '/content/mobilenet-transfer-learning/ThiefTFData/train/Thief.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/mobilenet-transfer-learning/ThiefTFData/train/Thief_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "3XZdTg37kZ5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Set configuration parameters for training the model:"
      ],
      "metadata": {
        "id": "P88y85KQnPCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You can change chosen model to deploy different models available in the TF2 object detection zoo\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2_320x320_coco17': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "        'batch_size': 16\n",
        "    }\n",
        "}\n",
        "chosen_model = 'ssd_mobilenet_v2_320x320_coco17'\n",
        "num_steps = 1800 #40000 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing.\n",
        "num_eval_steps = 500 #Perform evaluation after so many steps\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your trainin#g"
      ],
      "metadata": {
        "id": "pAGuKRqJnWlg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Load trained model weights from TensorFlow site, and the custom configuration file which I’ve prepared for this example:"
      ],
      "metadata": {
        "id": "50zI2WRgn-sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download pretrained weights\n",
        "%mkdir /content/deploy/\n",
        "%cd /content/deploy/\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "#Shorten the folder name,because long file paths are not yet supported :(\n",
        "os.rename('ssd_mobilenet_v2_320x320_coco17_tpu-8','mobilnetv2')"
      ],
      "metadata": {
        "id": "iWqnWoLSuj3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deploy\n",
        "download_config = '!wget https://raw.githubusercontent.com/tanhhkhcndn/mobilenet-transfer-learning/main/ssd_mobilenet_v2_320x320_coco17_tpu-8.config'\n",
        "!wget {download_config}"
      ],
      "metadata": {
        "id": "nO72ELpYoDqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare frozen model for retraining\n",
        "fine_tune_checkpoint = '/content/deploy/mobilnetv2/checkpoint/ckpt-0'\n",
        "pipeline_file = '/content/deploy/ssd_mobilenet_v2_320x320_coco17_tpu-8.config'\n",
        "model_dir = '/content/training/'\n",
        "\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)"
      ],
      "metadata": {
        "id": "oGIuYJgMvuEt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Run the training process:\n",
        "From my experience, loss function result with a value lower than0.2 is enough for a demo application."
      ],
      "metadata": {
        "id": "tDbl6fQnje2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "id": "asGs2dX8jhG_",
        "outputId": "71ecbe77-1855-471c-9aa6-197472034734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Step 1800 per-step time 5.522s\n",
            "I1201 07:45:57.621553 140310429614080 model_lib_v2.py:705] Step 1800 per-step time 5.522s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.99283457,\n",
            " 'Loss/localization_loss': 0.6150839,\n",
            " 'Loss/regularization_loss': 4.7656126,\n",
            " 'Loss/total_loss': 6.373531,\n",
            " 'learning_rate': 0.733333}\n",
            "I1201 07:45:57.621988 140310429614080 model_lib_v2.py:708] {'Loss/classification_loss': 0.99283457,\n",
            " 'Loss/localization_loss': 0.6150839,\n",
            " 'Loss/regularization_loss': 4.7656126,\n",
            " 'Loss/total_loss': 6.373531,\n",
            " 'learning_rate': 0.733333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Step 9: Save the retrained model:\n",
        "\n",
        "Exported model will be stored at output_directory. In this example the model will be exported to /content/fine_tuned_model.\n",
        "save fine_tune_model to local drive by zip"
      ],
      "metadata": {
        "id": "VMgRvdJeX5GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#run conversion script to save the retrained model:\n",
        "#Saved model will be in saved_model.pb file:\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = '/content/fine_tuned_model'\n",
        "\n",
        "#place the model weights you would like to export here\n",
        "last_model_path = '/content/training/'\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}"
      ],
      "metadata": {
        "id": "uPSq4V4WWJ0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/fine_tuned_model.zip /content/fine_tuned_model"
      ],
      "metadata": {
        "id": "O5Wcyt7xYEa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: Testing our retrained model:\n",
        "Step A: Import the images you want to test to the /content/test folder."
      ],
      "metadata": {
        "id": "l76LUHXDbG2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/test/\n",
        "%cd /content/test/\n",
        "!gdown 11vqszjiGxdgogvJ_lJ7wOrgUUaTYYPeC"
      ],
      "metadata": {
        "id": "RPFUujB1d3ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step B: Import visualization libraries and object detection functions:"
      ],
      "metadata": {
        "id": "GGU76jKQeo0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Wxxg83r-euFT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step C: Import our retrained model, its last training checkpoint and map object labels. For this example I chose ckpt-2 (second checkpoint)."
      ],
      "metadata": {
        "id": "sPlX0kq9e1vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Recover our saved model with the latest checkpoint:\n",
        "pipeline_config = pipeline_file\n",
        "#Put the last ckpt from training in here, don't use long pathnames:\n",
        "model_dir = '/content/training/ckpt-1'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore last checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "#ckpt.restore(os.path.join(model_dir))\n",
        "ckpt.restore(model_dir)\n",
        "\n",
        "#Function perform detection of the object on image in tensor format:\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "#Define function which performs detection:\n",
        "detect_fn = get_model_detection_function(detection_model)\n",
        "\n",
        "\n",
        "#map labels for inference decoding\n",
        "label_map_path = configs['eval_input_config'].label_map_path\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "metadata": {
        "id": "UFO3u5uvfHG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step D: Perform object detection on test images:"
      ],
      "metadata": {
        "id": "bSy-VnqIf2QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#run detector on test image\n",
        "#it takes a little longer on the first run and then runs at normal speed.\n",
        "import random\n",
        "\n",
        "#Define utility functions for presenting the results:\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "#Place your test images here:\n",
        "image_path = '/content/test/thiefTest.jpg'\n",
        "\n",
        "#Store test images in nmpy array:\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "#Convert images to tensor form:\n",
        "input_tensor = tf.convert_to_tensor(\n",
        "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "\n",
        "#Perform detection on the image in tensor format:\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "#Visualize the detection boxes on the image:\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'][0].numpy(),\n",
        "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.5,#0.5,#0.5\n",
        "      agnostic_mode=False,\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12,16))\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LU3Uwmowf35y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}